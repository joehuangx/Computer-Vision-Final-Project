{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COCO inference+eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EQIt-FxWHrXt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch, gc\n",
        "from PIL import Image\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "# import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "\n",
        "import torchvision\n",
        "from torchvision.io import read_image\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights, SSD300_VGG16_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "import json\n",
        "\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.ops import masks_to_boxes\n",
        "\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-CAF2T9xHrXw",
        "outputId": "f77fb55e-2f31-4a92-bace-e79c23fe7edd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SSD(\n",
              "  (backbone): SSDFeatureExtractorVGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "      (17): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "    )\n",
              "    (extra): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): ReLU(inplace=True)\n",
              "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (6): ReLU(inplace=True)\n",
              "        (7): Sequential(\n",
              "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (4): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "      (3-4): 2 x Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
              "  (head): SSDHead(\n",
              "    (classification_head): SSDClassificationHead(\n",
              "      (module_list): ModuleList(\n",
              "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4-5): 2 x Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (regression_head): SSDRegressionHead(\n",
              "      (module_list): ModuleList(\n",
              "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
              "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# eval_name = 'ori_eval.json'\n",
        "# eval_name = '0.05_eval.json' \n",
        "# eval_name = '0.10_eval.json' \n",
        "# eval_name = '0.15_eval.json' \n",
        "# eval_name = '0.20_eval.json' \n",
        "eval_name = '0.25_eval.json'\n",
        "# eval_name = '0.30_eval.json'\n",
        "\n",
        "# model = torchvision.models.detection.ssd300_vgg16(weights='DEFAULT')\n",
        "# model = torch.load(\"/home/Joe/MY/CV/CV_FINAL/now/model/0.05.pth\")\n",
        "# model = torch.load(\"/home/Joe/MY/CV/CV_FINAL/now/model/0.10.pth\")\n",
        "# model = torch.load(\"/home/Joe/MY/CV/CV_FINAL/now/model/0.15.pth\")\n",
        "# model = torch.load(\"/home/Joe/MY/CV/CV_FINAL/now/model/0.20.pth\")\n",
        "model = torch.load(\"/home/Joe/MY/CV/CV_FINAL/now/model/0.25.pth\")\n",
        "# model = torch.load(\"/home/Joe/MY/CV/CV_FINAL/now/model/0.30.pth\")\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xaEPZ62bHrXy"
      },
      "outputs": [],
      "source": [
        "# get rid of zero annotation samples\n",
        "# pick 10000 imgs from differnet type\n",
        "# => 125 imgs per type\n",
        "def no_zero_imgs(train):\n",
        "\n",
        "    no_zero_img = []\n",
        "\n",
        "    if train == True:\n",
        "        coco = COCO('../coco/annotations/instances_train2017.json')\n",
        "        img_load = coco.loadImgs(coco.getImgIds())\n",
        "        cat_type = coco.getCatIds()\n",
        "        for i in cat_type:\n",
        "            img_id_list = coco.getImgIds(catIds = i)\n",
        "            for j in range(125):\n",
        "                img_id = img_id_list[j]\n",
        "\n",
        "                if( len(coco.getAnnIds(img_id)) == 0 ):\n",
        "                    continue\n",
        "                no_zero_img.append(coco.loadImgs(ids= img_id)[0])\n",
        "\n",
        "    else:\n",
        "        coco = COCO('/home/Joe/MY/CV/CV_FINAL/anchor_pruning/data/coco/annotations/instances_val2017.json')\n",
        "        img_load = coco.loadImgs(coco.getImgIds())\n",
        "        img_id_list = coco.getImgIds()\n",
        "        for i in range(len(img_load)):\n",
        "            img_id = img_id_list[i]\n",
        "            if( len(coco.getAnnIds(img_id)) == 0 ):\n",
        "                continue\n",
        "            no_zero_img.append(coco.loadImgs(ids= img_id)[0])\n",
        "\n",
        "\n",
        "    return no_zero_img\n",
        "\n",
        "\n",
        "class CocoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, train):\n",
        "\n",
        "        if train == True:\n",
        "            self.ann_file = \"../coco/annotations/instances_train2017.json\"\n",
        "            self.imgs_dir = '../coco/images/train2017/'\n",
        "        else:\n",
        "            self.ann_file = '/home/Joe/MY/CV/CV_FINAL/anchor_pruning/data/coco/annotations/instances_val2017.json'\n",
        "            self.imgs_dir = '/home/Joe/MY/CV/CV_FINAL/anchor_pruning/data/coco/val2017/'\n",
        "\n",
        "        self.coco = COCO(self.ann_file)\n",
        "        self.img_load = no_zero_imgs(train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # process for images\n",
        "\n",
        "        img_name = self.img_load[idx]['file_name']\n",
        "        dir = self.imgs_dir + \"/\" + img_name\n",
        "        preprocess = SSD300_VGG16_Weights.COCO_V1.transforms()\n",
        "        Image = preprocess(read_image(dir))\n",
        "        img = Image\n",
        "        # for targets\n",
        "\n",
        "        img_id = self.img_load[idx]['id']\n",
        "        ann_ids = self.coco.getAnnIds(img_id)\n",
        "        num_detect = len(ann_ids)\n",
        "\n",
        "        d = {}\n",
        "        if  num_detect == 0:\n",
        "            print(\"wrong!\", img_id)\n",
        "\n",
        "\n",
        "        for j in range (num_detect):\n",
        "\n",
        "            box_now = self.coco.loadAnns(ann_ids)[j]['bbox']\n",
        "\n",
        "            new_box = torch.tensor( [box_now[0], box_now[1], box_now[0] + box_now[2], box_now[1] + box_now[3]] ).reshape(1, 4)\n",
        "            new_label = torch.tensor( self.coco.loadAnns(ann_ids)[j]['category_id'] ).reshape(1)\n",
        "\n",
        "            if j == 0:\n",
        "                temp_box = new_box\n",
        "                temp_label = new_label\n",
        "            else:\n",
        "                temp_box = torch.cat((temp_box, new_box), dim = 0)\n",
        "                temp_label = torch.cat((temp_label, new_label))\n",
        "\n",
        "        target = {}\n",
        "        target['boxes'] = temp_box\n",
        "        target['labels'] = temp_label\n",
        "        target['image_id'] = img_id\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_load)\n",
        "\n",
        "def custom_collate(data):\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZW4PQSwHrX2"
      },
      "source": [
        "# COCO inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YFsbzUDOHrX2",
        "outputId": "3475fd00-5d90-4def-8ae6-5ce3082d771e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.28s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.25s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4952"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = torch.utils.data.DataLoader(\n",
        "    CocoDataset(train=False),\n",
        "    batch_size = 1,\n",
        "    shuffle = False,\n",
        "    collate_fn = custom_collate,\n",
        "    pin_memory = False )\n",
        "\n",
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L-zOz3cnHrX3",
        "outputId": "0e17fbbb-999e-4cd2-a385-d94e22888d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "bbox_result = []\n",
        "for i, data in enumerate(test):\n",
        "\n",
        "    model.eval()\n",
        "    output = model([data[0][0].cuda()])\n",
        "\n",
        "    for j in range(len(output[0]['boxes'])):\n",
        "        temp_dic = {}\n",
        "        temp_dic['image_id'] = data[0][1]['image_id']\n",
        "        temp_dic['category_id'] = output[0]['labels'][j].item()\n",
        "        out_list = output[0]['boxes'][j].tolist()\n",
        "\n",
        "        out_list[2] = out_list[2] - out_list[0]\n",
        "        out_list[3] = out_list[3] - out_list[1]\n",
        "\n",
        "        out_list = [round(num, 2) for num in out_list]\n",
        "        temp_dic['bbox'] = out_list\n",
        "\n",
        "        temp_dic['score'] = round(output[0]['scores'][j].item(), 3)\n",
        "\n",
        "        bbox_result.append(temp_dic)\n",
        "\n",
        "    # if i % 50 == 0:\n",
        "    #     print(i)\n",
        "end = time.time()\n",
        "\n",
        "exe_time = end-start\n",
        "\n",
        "with open(eval_name, \"w\") as outfile:\n",
        "    json.dump(bbox_result, outfile)\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ga60ru6HrX3"
      },
      "source": [
        "## COCO evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8cBrC6GvHrX4",
        "outputId": "c6fb84b7-9da1-46fb-f122-816915ee3eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.37s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.46s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "test_ann_file = \"/home/Joe/MY/CV/CV_FINAL/anchor_pruning/data/coco/annotations/instances_val2017.json\"\n",
        "coco_gt = COCO(test_ann_file)\n",
        "prediction = coco_gt.loadRes(eval_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iny2F_8DHrX4",
        "outputId": "3ce1a118-e704-4ebe-d2f8-7c7e6a485769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=14.66s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=4.44s).\n",
            "0.25_eval.json\n",
            "Execute time: 79.42721581459045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n"
          ]
        }
      ],
      "source": [
        "cocoEval = COCOeval(coco_gt, prediction, 'bbox')\n",
        "cocoEval.evaluate()\n",
        "cocoEval.accumulate()\n",
        "\n",
        "print(eval_name)\n",
        "print(\"Execute time: \" + str(exe_time))\n",
        "\n",
        "cocoEval.summarize()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
