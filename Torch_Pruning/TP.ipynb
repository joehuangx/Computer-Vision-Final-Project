{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAl3EGjAdLUZ"
      },
      "source": [
        "# Torch pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "onqhgWFMfeT8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch_pruning as tp\n",
        "import os, sys\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torchvision.models.detection import ssd300_vgg16\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_prune(model, example_inputs, output_transform, model_name, ratio, model_save_path):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ori_size = tp.utils.count_params(model)\n",
        "    model.cpu().eval()\n",
        "    ignored_layers = []\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad_(True)\n",
        "\n",
        "    #########################################\n",
        "    # Ignore unprunable modules\n",
        "    #########################################\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear) and m.out_features == 1000:\n",
        "            ignored_layers.append(m)\n",
        "\n",
        "    if 'ssd' in model_name:\n",
        "        ignored_layers.append(model.head)\n",
        "        ignored_layers.append(model.backbone.extra)\n",
        "        ignored_layers.append(model.backbone.features[-2])\n",
        "\n",
        "    round_to = None\n",
        "    channel_groups = {}\n",
        "\n",
        "    unwrapped_parameters = None\n",
        "\n",
        "    #########################################\n",
        "    # Build network pruners\n",
        "    #########################################\n",
        "    importance = tp.importance.MagnitudeImportance(p=1)\n",
        "    pruner = tp.pruner.MagnitudePruner(\n",
        "        model,\n",
        "        example_inputs=example_inputs,\n",
        "        importance=importance,\n",
        "        iterative_steps=1,\n",
        "        pruning_ratio=ratio, # adjust the ratio as needed\n",
        "        global_pruning=False,\n",
        "        round_to=round_to,\n",
        "        unwrapped_parameters=unwrapped_parameters,\n",
        "        ignored_layers=ignored_layers,\n",
        "        channel_groups=channel_groups,\n",
        "    )\n",
        "\n",
        "    #########################################\n",
        "    # Pruning\n",
        "    #########################################\n",
        "    # print(\"==============Before pruning=================\")\n",
        "    # print(\"Model Name: {}\".format(model_name))\n",
        "    # print(model)\n",
        "\n",
        "    layer_channel_cfg = {}\n",
        "    for module in model.modules():\n",
        "        if module not in pruner.ignored_layers:\n",
        "            #print(module)\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                layer_channel_cfg[module] = module.out_channels\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                layer_channel_cfg[module] = module.out_features\n",
        "\n",
        "    pruner.step()\n",
        "\n",
        "    # print(\"==============After pruning=================\")\n",
        "    # print(model)\n",
        "\n",
        "    #########################################\n",
        "    # Testing\n",
        "    #########################################\n",
        "    with torch.no_grad():\n",
        "        if isinstance(example_inputs, dict):\n",
        "            out = model(**example_inputs)\n",
        "        else:\n",
        "            out = model(example_inputs)\n",
        "\n",
        "        if output_transform:\n",
        "            out = output_transform(out)\n",
        "        # print(\"{} Pruning: \".format(model_name))\n",
        "        \n",
        "        params_after_prune = tp.utils.count_params(model)\n",
        "        print(\"Params: %s => %s\" % (ori_size, params_after_prune))\n",
        "\n",
        "        if isinstance(out, (dict,list,tuple)):\n",
        "            # print(\"  Output:\")\n",
        "            for o in tp.utils.flatten_as_list(out):\n",
        "                # print(o.shape)\n",
        "                pass\n",
        "        else:\n",
        "            # print(\"  Output:\", out.shape)\n",
        "            pass\n",
        "        # print(\"------------------------------------------------------\\n\")\n",
        "\n",
        "    torch.save(model, model_save_path)\n",
        "    \n",
        "    print(\"model saved to file \\\"\"+model_save_path)\n",
        "\n",
        "\n",
        "    return ori_size, params_after_prune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agIHOiHQifGd",
        "outputId": "4dd02ec1-7420-4b22-b700-1a251f43aad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params: 35641826 => 35641826\n",
            "model saved to file \"0.0.pth\n"
          ]
        }
      ],
      "source": [
        "pparaDict = {}\n",
        "\n",
        "model = torchvision.models.detection.ssd300_vgg16(weights='DEFAULT')\n",
        "\n",
        "ratio = 0.0\n",
        "model_save_path = str(ratio)+'.pth'\n",
        "ori_para, after_para = my_prune(model, torch.randn(1,3,300,300),None,'ssd', ratio = ratio, model_save_path = model_save_path)\n",
        "pparaDict[ratio] = [ori_para, after_para]\n",
        "\n",
        "# print(pparaDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SSD                                      [200, 4]                  --\n",
              "├─GeneralizedRCNNTransform: 1-1          [1, 3, 300, 300]          --\n",
              "├─SSDFeatureExtractorVGG: 1-2            [1, 256, 1, 1]            512\n",
              "│    └─Sequential: 2-1                   [1, 512, 38, 38]          --\n",
              "│    │    └─Conv2d: 3-1                  [1, 54, 300, 300]         1,512\n",
              "│    │    └─ReLU: 3-2                    [1, 54, 300, 300]         --\n",
              "│    │    └─Conv2d: 3-3                  [1, 54, 300, 300]         26,298\n",
              "│    │    └─ReLU: 3-4                    [1, 54, 300, 300]         --\n",
              "│    │    └─MaxPool2d: 3-5               [1, 54, 150, 150]         --\n",
              "│    │    └─Conv2d: 3-6                  [1, 108, 150, 150]        52,596\n",
              "│    │    └─ReLU: 3-7                    [1, 108, 150, 150]        --\n",
              "│    │    └─Conv2d: 3-8                  [1, 108, 150, 150]        105,084\n",
              "│    │    └─ReLU: 3-9                    [1, 108, 150, 150]        --\n",
              "│    │    └─MaxPool2d: 3-10              [1, 108, 75, 75]          --\n",
              "│    │    └─Conv2d: 3-11                 [1, 217, 75, 75]          211,141\n",
              "│    │    └─ReLU: 3-12                   [1, 217, 75, 75]          --\n",
              "│    │    └─Conv2d: 3-13                 [1, 217, 75, 75]          424,018\n",
              "│    │    └─ReLU: 3-14                   [1, 217, 75, 75]          --\n",
              "│    │    └─Conv2d: 3-15                 [1, 217, 75, 75]          424,018\n",
              "│    │    └─ReLU: 3-16                   [1, 217, 75, 75]          --\n",
              "│    │    └─MaxPool2d: 3-17              [1, 217, 38, 38]          --\n",
              "│    │    └─Conv2d: 3-18                 [1, 435, 38, 38]          849,990\n",
              "│    │    └─ReLU: 3-19                   [1, 435, 38, 38]          --\n",
              "│    │    └─Conv2d: 3-20                 [1, 435, 38, 38]          1,703,460\n",
              "│    │    └─ReLU: 3-21                   [1, 435, 38, 38]          --\n",
              "│    │    └─Conv2d: 3-22                 [1, 512, 38, 38]          2,004,992\n",
              "│    │    └─ReLU: 3-23                   [1, 512, 38, 38]          --\n",
              "│    └─ModuleList: 2-2                   --                        --\n",
              "│    │    └─Sequential: 3-24             [1, 1024, 19, 19]         12,848,640\n",
              "│    │    └─Sequential: 3-25             [1, 512, 10, 10]          1,442,560\n",
              "│    │    └─Sequential: 3-26             [1, 256, 5, 5]            360,832\n",
              "│    │    └─Sequential: 3-27             [1, 256, 3, 3]            328,064\n",
              "│    │    └─Sequential: 3-28             [1, 256, 1, 1]            328,064\n",
              "├─SSDHead: 1-3                           [1, 8732, 91]             --\n",
              "│    └─SSDRegressionHead: 2-3            [1, 8732, 4]              --\n",
              "│    │    └─ModuleList: 3-29             --                        534,648\n",
              "│    └─SSDClassificationHead: 2-4        [1, 8732, 91]             --\n",
              "│    │    └─ModuleList: 3-30             --                        12,163,242\n",
              "├─DefaultBoxGenerator: 1-4               [8732, 4]                 --\n",
              "==========================================================================================\n",
              "Total params: 33,809,671\n",
              "Trainable params: 33,809,671\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 28.19\n",
              "==========================================================================================\n",
              "Input size (MB): 1.08\n",
              "Forward/backward pass size (MB): 180.24\n",
              "Params size (MB): 135.24\n",
              "Estimated Total Size (MB): 316.56\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model, (1,3,300,300))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VAl3EGjAdLUZ",
        "ZD_L8au5WYld",
        "BQu0zfnMXW1p"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
